import json
import os
import sys
import asyncio
import time
from pathlib import Path
from typing import Any, Dict, List

import pandas as pd
import plotly.express as px
import streamlit as st
import pydeck as pdk

# Allow importing workflow modules when running via Streamlit
sys.path.append(str(Path(__file__).resolve().parents[1]))
from workflows.integrated_orchestrator import IntegratedOrchestratorManagement  # type: ignore
from orchestrator.adapters import DetectionReActAdapter  # type: ignore

try:
    from langchain_ibm import WatsonxLLM  # type: ignore
except Exception:  # pragma: no cover - optional at runtime
    WatsonxLLM = None  # type: ignore


st.set_page_config(page_title="ArkWatson - Disaster Ops Center", layout="wide")


def load_latest_results() -> Dict[str, Any]:
    out_dir = Path(__file__).parents[2] / "integrated_demo_output"
    if not out_dir.exists():
        return {}
    latest_file = None
    latest_mtime = 0
    for f in out_dir.glob("integrated_orchestrator_results_*.json"):
        mtime = f.stat().st_mtime
        if mtime > latest_mtime:
            latest_mtime = mtime
            latest_file = f
    if not latest_file:
        return {}
    try:
        return json.loads(latest_file.read_text())
    except Exception:
        return {}


def render_map(classification: Dict[str, Any], monitoring: Dict[str, Any], unique_key: str = ""):
    # Use San Francisco coordinates as default since that's where the population zones are
    lat = monitoring.get("summary", {}).get("center_lat") or monitoring.get("center_lat") or monitoring.get("lat") or 37.7749
    lon = monitoring.get("summary", {}).get("center_lon") or monitoring.get("center_lon") or monitoring.get("lon") or -122.4194
    
    # Load population zones to show affected areas on map
    data_dir = Path(__file__).parents[2] / "data"
    zones_file = data_dir / "population_zones.csv"
    
    map_data = []
    if zones_file.exists():
        try:
            zones_df = pd.read_csv(zones_file)
            # Add all population zones to the map
            for _, zone in zones_df.iterrows():
                map_data.append({
                    "lat": zone["center_lat"],
                    "lon": zone["center_lon"],
                    "zone_name": zone["zone_name"],
                    "population": zone["population"]
                })
        except Exception as e:
            st.warning(f"Could not load population zones: {e}")
    
    # If no zones loaded, show center point
    if not map_data:
        map_data = [{"lat": lat, "lon": lon, "zone_name": "Center", "population": 0}]
    
    df = pd.DataFrame(map_data)
    view_state = pdk.ViewState(latitude=lat, longitude=lon, zoom=11)
    layer = pdk.Layer(
        "ScatterplotLayer",
        data=df,
        get_position=["lon", "lat"],
        get_radius=200,
        get_color=[200, 30, 0, 160],
        pickable=True,
    )
    deck = pdk.Deck(layers=[layer], initial_view_state=view_state, 
                   tooltip={"text": "Zone: {zone_name}\nPopulation: {population}"})
    st.pydeck_chart(deck, use_container_width=True, key=f"disaster_map_{unique_key}")


def render_bubbles(severity: Dict[str, Any], planning_result: Dict[str, Any], unique_key: str = ""):
    zones = planning_result.get("evacuation", {}).get("routes", {}).get("routes", [])
    if not zones:
        st.info("Run the integration with planning to see evacuation route capacity bubbles.")
        return
    df = pd.DataFrame([
        {
            "from_lat": r.get("from_location", [0, 0])[1],
            "from_lon": r.get("from_location", [0, 0])[0],
            "to_lat": r.get("to_location", [0, 0])[1],
            "to_lon": r.get("to_location", [0, 0])[0],
            "distance_km": r.get("distance_km", 0),
            "capacity_per_hour": r.get("capacity_per_hour", 0),
        }
        for r in zones
    ])
    fig = px.scatter(
        df,
        x="distance_km",
        y="capacity_per_hour",
        size="capacity_per_hour",
        color="distance_km",
        title="Evacuation Route Capacity vs Distance",
    )
    st.plotly_chart(fig, use_container_width=True, key=f"evacuation_bubbles_{unique_key}")


def _render_badge(text: str, color: str = "gray") -> None:
    colors = {
        "green": "#2e7d32",
        "red": "#b71c1c",
        "orange": "#ef6c00",
        "blue": "#1565c0",
        "gray": "#455a64",
        "purple": "#6a1b9a",
    }
    hex_color = colors.get(color, color)
    st.markdown(
        f"<span style='display:inline-block;padding:4px 10px;border-radius:999px;background:{hex_color};color:white;font-size:12px;font-weight:600'>{text}</span>",
        unsafe_allow_html=True,
    )


def render_classification_panel(classification: Dict[str, Any]):
    st.subheader("Classification")
    if not classification:
        st.info("No classification available yet.")
        return

    top_cols = st.columns([1, 1, 1])
    with top_cols[0]:
        st.metric("Disaster Type", classification.get("disaster_type", "unknown"))
    with top_cols[1]:
        st.metric("Confidence", f"{classification.get('confidence_score', 0)*100:.0f}%")
    with top_cols[2]:
        sev = classification.get("severity_level", "unknown")
        sev_color = "red" if sev in ["high", "critical", "extreme"] else ("orange" if sev == "moderate" else "green")
        _render_badge(f"Severity: {sev}", sev_color)

    confirm_cols = st.columns([1, 2])
    with confirm_cols[0]:
        requires_conf = classification.get("requires_confirmation", False)
        _render_badge("Needs Confirmation" if requires_conf else "No Confirmation Needed", "orange" if requires_conf else "green")
    with confirm_cols[1]:
        if classification.get("risk_factors"):
            st.write("Risk Factors")
            st.markdown("\n".join([f"- {rf}" for rf in classification.get("risk_factors", [])]))

    if classification.get("recommendations"):
        st.write("Recommendations")
        st.markdown("\n".join([f"- {rec}" for rec in classification.get("recommendations", [])]))

    with st.expander("Raw classification JSON"):
        st.code(json.dumps(classification, indent=2), language="json")


def render_severity_panel(severity: Dict[str, Any]):
    st.subheader("Severity")
    if not severity:
        st.info("No severity information available yet.")
        return

    level = severity.get("severity_level", "unknown")
    score = float(severity.get("severity_score", 0.0))

    cols = st.columns([1, 1])
    with cols[0]:
        st.metric("Severity Level", level)
        st.metric("Severity Score", f"{score:.2f}")
    with cols[1]:
        st.write("Risk Score")
        st.progress(min(max(int(score * 100), 0), 100))

    factors = severity.get("severity_factors", {})
    if factors:
        st.write("Key Factors")
        factors_df = pd.DataFrame({"factor": list(factors.keys()), "detail": list(factors.values())})
        st.dataframe(factors_df, use_container_width=True, hide_index=True)

    impact = severity.get("impact_assessment", {})
    if impact:
        st.write("Impact Assessment")
        impact_cols = st.columns(len(impact) or 1)
        for idx, (k, v) in enumerate(impact.items()):
            with impact_cols[idx % max(1, len(impact_cols))]:
                _render_badge(f"{k.replace('_',' ').title()}: {'Yes' if v else 'No'}", "red" if v else "gray")

    if severity.get("recommendations"):
        st.write("Actions")
        st.markdown("\n".join([f"- {rec}" for rec in severity.get("recommendations", [])]))

    with st.expander("Raw severity JSON"):
        st.code(json.dumps(severity, indent=2), language="json")


def render_monitoring_summary(monitoring: Dict[str, Any]):
    st.subheader("Monitoring Summary")
    if not monitoring:
        st.info("No monitoring summary available yet.")
        return
    cols = st.columns(3)
    with cols[0]:
        st.metric("Sources", monitoring.get("total_sources", 0))
    with cols[1]:
        st.metric("Total Alerts", monitoring.get("total_alerts", 0))
    with cols[2]:
        _render_badge(f"Polled: {monitoring.get('polled_at', 'n/a')}", "blue")


def render_routes_distribution(planning_result: Dict[str, Any], unique_key: str = ""):
    routes: List[Dict[str, Any]] = planning_result.get("evacuation", {}).get("routes", {}).get("routes", [])
    if not routes:
        return
    df = pd.DataFrame([
        {
            "distance_km": r.get("distance_km", 0.0),
            "capacity_per_hour": r.get("capacity_per_hour", 0.0),
        }
        for r in routes
    ])
    c1, c2 = st.columns(2)
    with c1:
        st.plotly_chart(px.histogram(df, x="distance_km", nbins=30, title="Route Distance Distribution"), use_container_width=True, key=f"route_dist_{unique_key}")
    with c2:
        st.plotly_chart(px.histogram(df, x="capacity_per_hour", nbins=30, title="Route Capacity Distribution"), use_container_width=True, key=f"route_cap_{unique_key}")


def render_deployments(planning_result: Dict[str, Any], unique_key: str = ""):
    deployments = planning_result.get("deployments", {}).get("deployments", [])
    if not deployments:
        st.info("No deployments generated yet.")
        return
    df = pd.DataFrame(deployments)
    # Metrics
    cols = st.columns(3)
    with cols[0]:
        st.metric("Total Deployments", len(df))
    with cols[1]:
        if "estimated_arrival_minutes" in df.columns:
            st.metric("Median ETA (min)", int(df["estimated_arrival_minutes"].median()))
    with cols[2]:
        st.metric("Priority Levels", df.get("priority_level", pd.Series(dtype=str)).nunique())

    # Priority distribution
    if "priority_level" in df.columns:
        pr_df = df["priority_level"].value_counts().reset_index()
        pr_df.columns = ["priority", "count"]
        st.plotly_chart(px.bar(pr_df, x="priority", y="count", title="Deployments by Priority"), use_container_width=True, key=f"dep_prio_{unique_key}")

    # Table preview
    view_cols = [c for c in ["team_id", "target_zone_id", "priority_level", "estimated_arrival_minutes", "coordination_instructions"] if c in df.columns]
    st.dataframe(df[view_cols].head(25), use_container_width=True)


def _run_async(coro):
    try:
        return asyncio.run(coro)
    except RuntimeError:
        loop = asyncio.get_event_loop()
        return loop.run_until_complete(coro)


def run_detection_only(lat: float, lon: float, radius_km: float, location_name: str, watsonx_config: Dict[str, Any], situation_description: str | None) -> Dict[str, Any]:
    detector = DetectionReActAdapter()
    result = _run_async(
        detector.run(
            lat=lat,
            lon=lon,
            radius_km=radius_km,
            location_name=location_name,
            watsonx_config=watsonx_config,
            situation_description=situation_description,
        )
    )
    return {
        "management_phase": "monitoring_only",
        "planning_triggered": False,
        "detection_summary": {
            "event_detected": bool(result.get("classification", {}).get("threat_detected", False)),
            "classification": result.get("classification", {}),
            "severity": result.get("severity", {}),
            "monitoring": result.get("monitoring_summary", {}),
        },
        "session_id": f"orch_{int(time.time())}",
        "timestamp": time.strftime("%Y-%m-%dT%H:%M:%S"),
    }


def run_complete_response(lat: float, lon: float, radius_km: float, location_name: str, watsonx_config: Dict[str, Any], situation_description: str | None) -> Dict[str, Any]:
    manager = IntegratedOrchestratorManagement()
    results = _run_async(
        manager.run_complete_disaster_management(
            monitoring_regions=[{
                "name": location_name,
                "center_lat": lat,
                "center_lon": lon,
                "radius_km": radius_km,
            }],
            session_id=f"orch_{int(time.time())}",
            config={"watsonx_config": watsonx_config},
            situation_description=situation_description,
        )
    )
    return results


def summarize_for_chat(results: Dict[str, Any]) -> List[str]:
    lines: List[str] = []
    ds = results.get("detection_summary", {})
    c = ds.get("classification", {})
    s = ds.get("severity", {})
    lines.append(f"Threat: {'YES' if c.get('threat_detected') else 'NO'} | Type: {c.get('disaster_type','unknown')} | Confidence: {c.get('confidence_score',0):.2f} | Severity: {c.get('severity_level','low')}")
    if c.get("risk_factors"):
        lines.append("Risk Factors: " + ", ".join(c.get("risk_factors", [])[:3]))
    if s:
        lines.append(f"Severity Score: {s.get('severity_score', 0)} | Population At Risk: {s.get('population_at_risk', 0):,} | Critical Infra: {s.get('critical_infrastructure_count', 0)}")
        if s.get("recommendations"):
            lines.append("Actions: " + ", ".join(s.get("recommendations", [])[:3]))
    ps = results.get("planning_summary", {})
    if ps:
        lines.append(f"Planning: deployments={ps.get('deployments_created', 0)}, routes={ps.get('routes', 0)}")
    return lines


def summarize_with_watsonx(results: Dict[str, Any], model_id: str, watsonx_config: Dict[str, Any]) -> str:
    try:
        if WatsonxLLM is None:
            raise RuntimeError("WatsonxLLM not available")
        params = {
            "decoding_method": "sample",
            "max_new_tokens": 300,
            "temperature": 0.3,
            "top_p": 0.9,
            "top_k": 50,
        }
        llm = WatsonxLLM(
            model_id=model_id,
            url=watsonx_config.get("url") or os.environ.get("WATSONX_URL", "https://us-south.ml.cloud.ibm.com"),
            apikey=watsonx_config.get("api_key") or os.environ.get("WATSONX_APIKEY"),
            project_id=watsonx_config.get("project_id") or os.environ.get("WATSONX_PROJECT_ID"),
            params=params,
        )
        prompt = (
            "You are an incident commander assistant. Summarize the following disaster management JSON into 6-8 concise bullet points for executives. "
            "Include: current phase, threat type and confidence, severity level and key drivers, whether planning was triggered, deployments/routes counts, and immediate recommended actions.\n\nJSON:\n"
            + json.dumps(results)[:15000]
        )
        return str(llm.invoke(prompt))
    except Exception as e:  # Fallback deterministic summary
        return "\n".join(summarize_for_chat(results)) + f"\n(Note: model summary unavailable: {e})"


def main():
    st.title("ArkWatson - Disaster Operations Center")
    st.caption("Live monitoring, classification, and response planning dashboard")

    auto_refresh = st.sidebar.checkbox("Auto-refresh", value=True, key="auto_refresh_checkbox")
    refresh_sec = st.sidebar.slider("Refresh interval (sec)", 5, 60, 10, key="refresh_interval_slider")

    placeholder = st.empty()
    while True:
        placeholder.empty()
        with placeholder.container():
            data = st.session_state.get("latest_results") or load_latest_results()
            if not data:
                st.info("No integrated results found yet. Run demo_orchestrator_integration.py to generate outputs.")
                time.sleep(refresh_sec)
                continue

            left, right = st.columns([1, 2])
            with left:
                # Chat-driven workflow runner
                st.subheader("Chat-Orchestrate")
                if "messages" not in st.session_state:
                    st.session_state["messages"] = []

                model_id = st.selectbox(
                    "Granite model",
                    options=[
                        "ibm/granite-3-8b-instruct",
                        "ibm/granite-13b-instruct-v2",
                        "ibm/granite-13b-chat-v2",
                        "ibm/granite-20b-multilingual",
                    ],
                    index=1,
                    help="Model used for classification and final summary",
                    key="granite_model_selector"
                )
                mode = st.radio(
                    "Workflow",
                    options=["Detection (ReAct)", "Complete Response (Plan-Act)"],
                    index=1,
                    horizontal=False,
                    key="workflow_mode_selector"
                )
                region = st.text_input("Region", value="San Francisco Bay Area", key="region_input")
                lat = st.number_input("Lat", value=37.7749, format="%0.6f", key="lat_input")
                lon = st.number_input("Lon", value=-122.4194, format="%0.6f", key="lon_input")
                radius = st.number_input("Radius (km)", value=100.0, step=10.0, key="radius_input")
                with st.expander("Watsonx configuration"):
                    api_key = st.text_input("API key", value=os.environ.get("WATSONX_APIKEY", ""), type="password", key="watsonx_api_key")
                    url = st.text_input("URL", value=os.environ.get("WATSONX_URL", "https://us-south.ml.cloud.ibm.com"), key="watsonx_url")
                    project_id = st.text_input("Project ID", value=os.environ.get("WATSONX_PROJECT_ID", ""), key="watsonx_project_id")

                for msg in st.session_state["messages"]:
                    st.chat_message(msg["role"]).markdown(msg["content"])

                prompt = st.chat_input("Describe the situation or ask to run a new analysis…", key="chat_input")
                if prompt:
                    st.session_state["messages"].append({"role": "user", "content": prompt})
                    st.chat_message("user").markdown(prompt)

                    with st.chat_message("assistant"):
                        st.write("Running workflow…")
                        watsonx_cfg = {"api_key": api_key, "url": url, "project_id": project_id, "model_id": model_id}
                        if mode.startswith("Detection"):
                            results = run_detection_only(lat, lon, float(radius), region, watsonx_cfg, prompt)
                        else:
                            results = run_complete_response(lat, lon, float(radius), region, watsonx_cfg, prompt)

                        # Persist results so right-hand visualizations update
                        st.session_state["latest_results"] = results

                        # Stage summaries
                        for line in summarize_for_chat(results):
                            st.markdown(f"- {line}")

                        # Final LLM summary
                        st.markdown("\n**Model Summary**")
                        final_summary = summarize_with_watsonx(results, model_id, watsonx_cfg)
                        st.markdown(final_summary)
                        st.session_state["messages"].append({"role": "assistant", "content": "\n".join(summarize_for_chat(results)) + "\n\n" + final_summary})
                st.subheader("Status")
                st.metric("Phase", data.get("management_phase", "unknown"))
                st.metric("Planning Triggered", str(data.get("planning_triggered", False)))
                st.write("Session:", data.get("session_id"))
                st.write("Timestamp:", data.get("timestamp"))

                ds = data.get("detection_summary", {})
                classification = ds.get("classification", {})
                render_classification_panel(classification)

                severity = ds.get("severity", {})
                render_severity_panel(severity)

                monitoring = ds.get("monitoring", {})
                render_monitoring_summary(monitoring)

            with right:
                # Create unique key for this refresh cycle
                unique_key = str(int(time.time() * 1000))  # Use millisecond timestamp
                
                st.subheader("Map")
                monitoring = ds.get("monitoring", {})
                render_map(classification, monitoring, unique_key)

                st.subheader("Evacuation Capacity Bubbles")
                render_bubbles(severity, data.get("planning_result", {}), unique_key)

                st.subheader("Routes & Deployments")
                render_routes_distribution(data.get("planning_result", {}), unique_key)
                render_deployments(data.get("planning_result", {}), unique_key)

        if not auto_refresh:
            break
        time.sleep(refresh_sec)


if __name__ == "__main__":
    main()


